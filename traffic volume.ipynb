{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67a2653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather value counts before filling nulls:\n",
      " weather\n",
      "Clouds          15144\n",
      "Clear           13383\n",
      "Mist             5942\n",
      "Rain             5665\n",
      "Snow             2875\n",
      "Drizzle          1818\n",
      "Haze             1359\n",
      "Thunderstorm     1033\n",
      "Fog               912\n",
      "NaN                49\n",
      "Smoke              20\n",
      "Squall              4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "âœ… Processed data sample:\n",
      "    holiday    temp  rain  snow  weather  traffic_volume  day  month  year  \\\n",
      "0        7  288.28   0.0   0.0        1            5545    2     10  2012   \n",
      "1        7  289.36   0.0   0.0        1            4516    2     10  2012   \n",
      "2        7  289.58   0.0   0.0        1            4767    2     10  2012   \n",
      "3        7  290.13   0.0   0.0        1            5026    2     10  2012   \n",
      "4        7  291.14   0.0   0.0        1            4918    2     10  2012   \n",
      "\n",
      "   hours  minutes  seconds  \n",
      "0      9        0        0  \n",
      "1     10        0        0  \n",
      "2     11        0        0  \n",
      "3     12        0        0  \n",
      "4     13        0        0  \n",
      "âœ… Models saved successfully in your project folder.\n",
      "\n",
      "ðŸ“Š Model R^2 Scores:\n",
      "Linear Regression: 0.1389\n",
      "Decision Tree: 0.7197\n",
      "Random Forest: 0.8418\n",
      "SVR: 0.2448\n",
      "XGBoost: 0.8411\n"
     ]
    }
   ],
   "source": [
    "# ðŸš¦ Advanced Traffic Volume Estimation Project\n",
    "\n",
    "# 1. Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import linear_model, tree, ensemble, svm, metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost\n",
    "import joblib  # For saving models\n",
    "\n",
    "# 2. Importing the data\n",
    "data = pd.read_csv(r\"C:\\Users\\venka\\Downloads\\traffic_volume_project\\traffic volume.csv\")\n",
    "\n",
    "# 3. Filling missing numerical values with mean\n",
    "for col in ['temp', 'rain', 'snow']:\n",
    "    data[col] = data[col].fillna(data[col].mean())\n",
    "\n",
    "# 4. Filling missing categorical values in 'weather' with 'Clouds'\n",
    "print(\"Weather value counts before filling nulls:\\n\", data['weather'].value_counts(dropna=False))\n",
    "data['weather'] = data['weather'].fillna('Clouds')\n",
    "\n",
    "# 5. Filling missing 'holiday' values with 'None' and encoding as category codes\n",
    "data['holiday'] = data['holiday'].fillna('None')\n",
    "data['holiday'] = data['holiday'].astype('category').cat.codes\n",
    "\n",
    "# 6. Splitting date into day, month, year\n",
    "date_split = data['date'].str.split(\"-\", expand=True)\n",
    "date_split.columns = ['day', 'month', 'year']\n",
    "data = pd.concat([data, date_split], axis=1)\n",
    "\n",
    "# 7. Splitting Time into hours, minutes, seconds\n",
    "time_split = data['Time'].str.split(\":\", expand=True)\n",
    "time_split.columns = ['hours', 'minutes', 'seconds']\n",
    "data = pd.concat([data, time_split], axis=1)\n",
    "\n",
    "# 8. Dropping original 'date' and 'Time' columns\n",
    "data = data.drop(columns=['date', 'Time'])\n",
    "\n",
    "# 9. Encoding categorical 'weather' column into numeric codes\n",
    "data['weather'] = data['weather'].astype('category').cat.codes\n",
    "\n",
    "# 10. Converting all columns to numeric types if necessary\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 11. Dropping any remaining rows with nulls after conversions\n",
    "data = data.dropna()\n",
    "\n",
    "# 12. Viewing processed data sample\n",
    "print(\"\\nâœ… Processed data sample:\\n\", data.head())\n",
    "\n",
    "# 13. Separating target and features\n",
    "y = data['traffic_volume']\n",
    "x = data.drop(columns=['traffic_volume'], axis=1)\n",
    "\n",
    "# 14. Scaling features for better model performance using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "x = pd.DataFrame(x_scaled, columns=x.columns)\n",
    "\n",
    "# Saving scaler for future use\n",
    "joblib.dump(scaler, r\"C:\\Users\\venka\\Downloads\\traffic_volume_project\\scaler.pkl\")\n",
    "\n",
    "# 15. Splitting data into train-test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 16. Defining models\n",
    "lin_reg = linear_model.LinearRegression()\n",
    "Dtree = tree.DecisionTreeRegressor(random_state=42)\n",
    "Rand = ensemble.RandomForestRegressor(random_state=42)\n",
    "svr_model = svm.SVR()\n",
    "XGB = xgboost.XGBRegressor(random_state=42)\n",
    "\n",
    "# 17. Training models\n",
    "lin_reg.fit(x_train, y_train)\n",
    "Dtree.fit(x_train, y_train)\n",
    "Rand.fit(x_train, y_train)\n",
    "svr_model.fit(x_train, y_train)\n",
    "XGB.fit(x_train, y_train)\n",
    "\n",
    "# 18. Saving trained models for future deployment\n",
    "joblib.dump(lin_reg, r\"C:\\Users\\venka\\Downloads\\traffic_volume_project\\lin_reg_model.pkl\")\n",
    "joblib.dump(Dtree, r\"C:\\Users\\venka\\Downloads\\traffic_volume_project\\decision_tree_model.pkl\")\n",
    "joblib.dump(Rand, r\"C:\\Users\\venka\\Downloads\\traffic_volume_project\\random_forest_model.pkl\")\n",
    "joblib.dump(svr_model, r\"C:\\Users\\venka\\Downloads\\traffic_volume_project\\svr_model.pkl\")\n",
    "joblib.dump(XGB, r\"C:\\Users\\venka\\Downloads\\traffic_volume_project\\xgboost_model.pkl\")\n",
    "\n",
    "print(\"âœ… Models saved successfully in your project folder.\")\n",
    "\n",
    "# 19. Predicting on test data\n",
    "predictions = {\n",
    "    \"Linear Regression\": lin_reg.predict(x_test),\n",
    "    \"Decision Tree\": Dtree.predict(x_test),\n",
    "    \"Random Forest\": Rand.predict(x_test),\n",
    "    \"SVR\": svr_model.predict(x_test),\n",
    "    \"XGBoost\": XGB.predict(x_test)\n",
    "}\n",
    "\n",
    "# 20. Evaluating model performance using R^2 score\n",
    "print(\"\\nðŸ“Š Model R^2 Scores:\")\n",
    "for model_name, preds in predictions.items():\n",
    "    score = metrics.r2_score(y_test, preds)\n",
    "    print(f\"{model_name}: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c3fe97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming your scaler object is named 'scaler'\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb314c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('xgboost_model.pkl', 'wb') as f:\n",
    "    pickle.dump(XGB, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "739ccaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "with open('scaler.pkl', 'rb') as f:\n",
    "    loaded_scaler = pickle.load(f)\n",
    "\n",
    "print(\"Scaler loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61496066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_4200\\1352175926.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mean(), inplace=True)\n",
      "C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_4200\\1352175926.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['weather'].fillna('Clouds', inplace=True)\n",
      "C:\\Users\\venka\\AppData\\Local\\Temp\\ipykernel_4200\\1352175926.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['holiday'].fillna('None', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model and scaler saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# save_model.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(r\"C:\\Users\\venka\\Downloads\\traffic_volume_project\\traffic volume.csv\")\n",
    "\n",
    "# Preprocessing\n",
    "for col in ['temp', 'rain', 'snow']:\n",
    "    data[col].fillna(data[col].mean(), inplace=True)\n",
    "data['weather'].fillna('Clouds', inplace=True)\n",
    "data['holiday'].fillna('None', inplace=True)\n",
    "\n",
    "# Date split\n",
    "date_split = data['date'].str.split(\"-\", expand=True)\n",
    "date_split.columns = ['day', 'month', 'year']\n",
    "data = pd.concat([data, date_split], axis=1)\n",
    "\n",
    "# Time split\n",
    "time_split = data['Time'].str.split(\":\", expand=True)\n",
    "time_split.columns = ['hours', 'minutes', 'seconds']\n",
    "data = pd.concat([data, time_split], axis=1)\n",
    "\n",
    "# Drop unused columns\n",
    "data.drop(columns=['date', 'Time'], inplace=True)\n",
    "\n",
    "# Encode categoricals\n",
    "data['weather'] = data['weather'].astype('category').cat.codes\n",
    "data['holiday'] = data['holiday'].astype('category').cat.codes\n",
    "\n",
    "# Ensure all numeric\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Features and target\n",
    "y = data['traffic_volume']\n",
    "x = data.drop(columns=['traffic_volume'], axis=1)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "Rand = ensemble.RandomForestRegressor(random_state=42)\n",
    "Rand.fit(x_train, y_train)\n",
    "\n",
    "# Save model and scaler\n",
    "pickle.dump(Rand, open('RandomForest_model.pkl', 'wb'))\n",
    "pickle.dump(scaler, open('scaler.pkl', 'wb'))\n",
    "\n",
    "print(\"âœ… Model and scaler saved successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
